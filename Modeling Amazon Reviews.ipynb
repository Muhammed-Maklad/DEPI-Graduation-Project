{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c0b647-027e-4696-8eca-6a2917fe57d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15dee367-608b-4968-b21f-ccd5eaaef952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import gc\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb9b0a6-6768-4b86-9f81-e2be87e8a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lazy = (pl.scan_csv('cleaned_amazon_reviews.csv')  # Lazy loading the CSV\n",
    "           .filter(pl.col('language') == 'english')  # Filter English reviews\n",
    "           .drop_nulls(subset=['cleaned_text', 'title'])  # Drop null values\n",
    "           .unique(subset=['cleaned_text'])  # Drop duplicates based on 'cleaned_text'\n",
    "           .with_columns(pl.col('label').replace({2: 1, 1: 0}))  # Replace label values\n",
    "           .select(['text', 'label'])  # Select relevant columns\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c182567-cd3a-4b9e-a9a6-f3f0337456cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_lazy.collect()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d741784-5602-4fb9-a390-812e936981b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9c0c38-4651-4974-b555-7e5c2279b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c50fb1af-5c1a-4f07-9a5b-a2317d723100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_pandas \n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca76b6c5-ce15-40e1-9cbe-3bbbc8ac5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = dataset.train_test_split(test_size=0.3)\n",
    "val_test_split = train_test_split['test'].train_test_split(test_size=2/3)\n",
    "final_splits = {\n",
    "    'train': train_test_split['train'],\n",
    "    'validation': val_test_split['train'],\n",
    "    'test': val_test_split['test']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "754eb5c7-11d7-4a7f-b7ac-58cfc2532e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670bbf0059704e77aeb7b6da52b05300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\envs\\roberta_env\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff173271afd49d582168610889c4500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf43ea5c615144e09fc1f02eb8799aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4a699e77d148b39189ffeb07cb8955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f877ce7a933d43e782707478553837ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2787731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2dd667b21d54af9aa0f239ce0528f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/398247 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8179ea4cb2064b229db6e63402789348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/796496 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return distilbert_tokenizer(examples['text'], truncation=True, padding='max_length')\n",
    "tokenized_datasets = {\n",
    "    'train': final_splits['train'].map(tokenize_function, batched=True),\n",
    "    'validation': final_splits['validation'].map(tokenize_function, batched=True),\n",
    "    'test': final_splits['test'].map(tokenize_function, batched=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31107e3f-f1ba-493f-b85c-1586dd110b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e1d9d15c354cd5877bc2beded1de8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/17 shards):   0%|          | 0/2787731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets['train'].save_to_disk('datasets/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "535a02e9-f339-421e-b617-28ad64af67c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb57c5b800ac478ea49a0b7a006f3f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/5 shards):   0%|          | 0/796496 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets['test'].save_to_disk('datasets/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a88af7d9-cacc-43b5-aa52-d852a1e0d672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9306f073599d41b68a9ff76c1f3acc75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/398247 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets['validation'].save_to_disk('datasets/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed3111c5-9caf-4758-be70-0d0b5591da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in tokenized_datasets:\n",
    "    tokenized_datasets[split].set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33e19a57-b3df-47eb-bd88-fc2a9a01a98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "D:\\conda\\envs\\roberta_env\\lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)  # Adjust num_labels as needed\n",
    "\n",
    "# Step 6: Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16, #Might have done it in 32 but this would use shared memory which destroys the performance.\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Initialize the hugging face Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    tokenizer=distilbert_tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dacc34e-c1fe-46e5-9cac-6cc9d52651ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='174234' max='174234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [174234/174234 18:45:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.119227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=174234, training_loss=0.13886891061075074, metrics={'train_runtime': 67534.089, 'train_samples_per_second': 41.279, 'train_steps_per_second': 2.58, 'total_flos': 3.6928347372268954e+17, 'train_loss': 0.13886891061075074, 'epoch': 1.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2676c95c-154c-4465-8a77-20e114d8fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(r\"D:\\PythonProjects\\DEPI Grad Project\\FinetunedModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "228018b9-aa40-42c2-880d-f575a734f344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49781' max='49781' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49781/49781 1:36:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11957396566867828, 'eval_runtime': 5763.0611, 'eval_samples_per_second': 138.207, 'eval_steps_per_second': 8.638, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Evaluate the model on the test dataset\n",
    "test_results = trainer.evaluate(eval_dataset=tokenized_datasets['test'])\n",
    "# Step 12: Print the test results\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "746b343f-880c-491d-ad7b-d54648580439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c383565-f942-4fbb-a191-69c91b994e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "device = torch.device(\"cuda\")\n",
    "sentence = \"I liked this work more than anything but it had a couple flaws\"\n",
    "\n",
    "# Tokenize the input sentence\n",
    "inputs = distilbert_tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# Move the inputs to the correct device (CPU or GPU)\n",
    "input_ids = inputs[\"input_ids\"].to(device)\n",
    "attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():  # No need to calculate gradients during inference\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Convert logits to probabilities\n",
    "probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = torch.argmax(probs, dim=-1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6e61124-300b-45f3-bf46-2b58628ad989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: Positive\n"
     ]
    }
   ],
   "source": [
    "labels = [\"Negative\", \"Positive\"]  # Example for binary classification\n",
    "predicted_label = labels[predicted_class]\n",
    "\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1ec01a9-5b3c-4905-ba7c-a8043ba6a97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\envs\\roberta_env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from transformers import  MarianMTModel, MarianTokenizer\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import whisper\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "translator = GoogleTranslator(source='ar', target='en')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "whisper_model = whisper.load_model(\"medium\").to(device)\n",
    "model_directory = r\"D:\\PythonProjects\\DEPI Grad Project\\FinetunedModel\"\n",
    "tokenizer_bert = DistilBertTokenizer.from_pretrained(model_directory)\n",
    "model_bert = DistilBertForSequenceClassification.from_pretrained(model_directory).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11a7e78b-2072-4955-bf1c-4593b9253e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(save_output=False, output_filename='recorded_audio.wav', duration=5):\n",
    "    fs = 16000  # Sample rate (Whisper requires 16kHz)\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='float32')\n",
    "    sd.wait()  # Wait for the recording to finish\n",
    "    print(\"Recording finished\")\n",
    "    if save_output:\n",
    "        wav.write(output_filename, fs, (audio * 32767).astype(np.int16))\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fae7fef-05dd-42b2-b114-a2cf65ed9af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(audio, model_size=\"medium\"):\n",
    "    audio = np.squeeze(audio)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(whisper_model.device) # whisper (and most ASR models) uses log scaled mel spectrogram \n",
    "    options = whisper.DecodingOptions(language=\"en\")  # Specify 'en' for English transcription\n",
    "    result = whisper.decode(whisper_model, mel, options)\n",
    "    return result.text  # Return only the transcribed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec994ca3-0f1a-4415-971b-8e54c676c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(transcription):\n",
    "    if(any('\\u0600' <= char <= '\\u06FF' for char in transcription)):\n",
    "        transcription = translator.translate(transcription)\n",
    "    inputs = tokenizer_bert(transcription, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    \n",
    "    # Move inputs to GPU if available\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model_bert(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1)\n",
    "    \n",
    "    # Define class labels (adjust as per your fine-tuned model's output)\n",
    "    labels = ['negative', 'positive']\n",
    "    return labels[predicted_class.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0bdcdb01-fd1b-4c34-baa0-b2fb91d64218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished\n"
     ]
    }
   ],
   "source": [
    "audio = record_audio(3)\n",
    "trans = transcribe(audio = audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb8fdf1d-9261-4edb-a696-edc549899de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].str[0:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52aa5a11-febd-496a-aaae-60620aba5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['content'].apply(classify_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
